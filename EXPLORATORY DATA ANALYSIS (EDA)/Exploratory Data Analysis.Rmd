---
title: "Análisis exploratorio de datos"
author: "Mauricio Vazquez"
date: '2025-03-14'
output:
  pdf_document:
    latex_engine: xelatex
---

***Link del repositorio de GitHub: https://github.com/MauricioVazquezM/Data_Visualization_Course_Project***

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE, fig.width=10)

# Libraries
library(MASS)  
library(ggplot2)
library(GGally)
library(mclust)
library(kableExtra)
library(FactoMineR)
library(knitr)
library(caret)
library(dplyr)
library(gridExtra)
library(corrplot)
library(ggcorrplot)
library(car)
library(lmtest)
```

```{r, echo=FALSE}
# Lectura de los datos
data <- read.csv("C:\\Users\\mauva\\OneDrive\\Documents\\ITAM\\10mo Semestre\\VISUALIZACION DE LA INFORMACION\\CODIGO\\PROJECT REPOSITORY\\Data_Visualization_Course_Project\\DATA\\ESGData.csv")
colnames(data) <- colnames(data) %>%
  tolower() %>%                       
  gsub("\\.", "_", .) %>%               
  gsub("^x(\\d{4})$", "\\1", .)   
# head(data)
```

<br>

## Objetivo

* El objetivo principal de este analisis explorartio es comprender y visualizar la estructura de los datos para extraer información relevante. Se busca identificar tendencias y patrones en problemas globales, explorar relaciones entre variables clave, y realizar comparaciones entre distintos países y regiones. Además, el análisis permitirá evaluar el impacto de eventos globales en los datos.

<br>

## Primeras observaciones

***Descripción*** 

El dataset seleccionado proviene del Banco Mundial y contiene datos sobre indicadores ambientales, sociales y de gobernanza (ESG) a nivel país y región. Con una estructura de aproximadamente 16000 filas y un total de 67 columnas, permite analizar la evolución de diversas métricas clave desde 1960 hasta 2020. 

<br>

***Columnas principales***

```{r echo=FALSE}
# Descripcion columnas principales
tabla_columnas <- data.frame(
  Variable = c("Country.Name", "Country.Code", "Indicator.Name", "Indicator.Code",
               "X1960 – X2020", "X2050", "X"),
  Descripción = c("Nombre del país o región",
                  "Código de tres letras asignado a cada país",
                  "Nombre del indicador (ej. emisiones de CO₂, acceso a electricidad)",
                  "Código asociado al indicador",
                  "Valores anuales del indicador correspondiente para cada país",
                  "Proyecciones para 2050 (si están disponibles)",
                  "Columna vacía (posiblemente residual de la extracción de datos)")
)

# Tabla descripcion
tabla_columnas %>%
  kable(format = "latex", booktabs = TRUE, caption = "Descripción de las columnas del dataset") %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```
  
<br>

\newpage

## Análisis exploratorio de datos

***Análisis univariado de los datos***

<br>

```{r echo=FALSE}
# Funcion de analisis univariado
univar_analisis <- function(data) {
  results <- list()
  
  for (feature in colnames(data)) {
    data_type <- class(data[[feature]])[1]
    
    total <- nrow(data)
    nan_count <- sum(is.na(data[[feature]]))
    no_missings <- total - nan_count
    pct_missings <- nan_count / total
    
    if (is.numeric(data[[feature]])) {
      promedio <- round(mean(data[[feature]], na.rm = TRUE),2)
      desv_estandar <- round(sd(data[[feature]], na.rm = TRUE),2)
      varianza <- round(var(data[[feature]], na.rm = TRUE),2)
      minimo <- min(data[[feature]], na.rm = TRUE)
      p10 <- quantile(data[[feature]], 0.10, na.rm = TRUE)
      q1 <- quantile(data[[feature]], 0.25, na.rm = TRUE)
      mediana <- quantile(data[[feature]], 0.50, na.rm = TRUE)
      q3 <- quantile(data[[feature]], 0.75, na.rm = TRUE)
      p90 <- quantile(data[[feature]], 0.90, na.rm = TRUE)
      maximo <- max(data[[feature]], na.rm = TRUE)
      
      inf_count <- sum(is.infinite(data[[feature]]) & data[[feature]] > 0)
      neg_inf_count <- sum(is.infinite(data[[feature]]) & data[[feature]] < 0)
    } else {
      promedio <- NA
      desv_estandar <- NA
      varianza <- NA
      minimo <- NA
      p10 <- NA
      q1 <- NA
      mediana <- NA
      q3 <- NA
      p90 <- NA
      maximo <- NA
    }
    
    results[[length(results) + 1]] <- list(
      
      Variable = feature,
      Total = total,
      No_Missings = no_missings,
      Missings = nan_count,
      Pct_Missings = pct_missings,
      Promedio = promedio,
      Desv_Std = desv_estandar,
      Varianza = varianza,
      Minimo = minimo,
      p10 = p10,
      q1 = q1,
      Mediana = mediana,
      q3 = q3,
      p90 = p90,
      Maximo = maximo
    )
  }
  
  result_df <- do.call(rbind, lapply(results, as.data.frame))
  
  rownames(result_df) <- NULL
  
  return(result_df)
  
}

# Seleccionar las columnas para el análisis
cols_to_analyze <- c("country_name", "country_code", "indicator_name", "indicator_code",
                     "1960", "1970", "1980", "1990", "2000", "2010", "2020")

# Filtrar solo las columnas relevantes
data_filtered <- data[, cols_to_analyze, drop = FALSE]

# Aplicar la función de análisis univariado
resultados <- univar_analisis(data_filtered)

# Separar el análisis en dos partes
resultados_parte1 <- resultados[, c("Variable", "Total", "No_Missings", "Missings", "Pct_Missings")]

# resultados_parte2 <- resultados[, c("Minimo", "p10", "q1", "Mediana", "q3", "p90", "Maximo")]

# Mostrar los resultados en dos tablas separadas por margenes de pagina
resultados_parte1 %>%
  kable(caption = "Análisis de valores nulos", booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```

- El análisis de valores nulos muestra que las variables categóricas no presentan valores nulos, mientras que las variables numéricas (años) tienen una alta proporción de valores nulos. Especialmente, en los años 1960 (91.55%) y 2020 (97.10%). A medida que avanzan los años, la disponibilidad de datos mejora, con una reducción gradual de valores nulos, destacando que desde el 2000 los datos son estan mas completos. Esto nos indica que muchos indicadores comenzaron a ser medidos en décadas recientes. 

<br>

***Visualización de las variables***